{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d471a5a1",
   "metadata": {},
   "source": [
    "# Entrenamiento de modelos YOLO\n",
    "\n",
    "Entrenamiento de las versiones n, s y m de YOLOv8 para deteccion de lesiones en imagenes del dataset ISIC 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b251b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b1dc25",
   "metadata": {},
   "source": [
    "## Preparacion del entorno\n",
    "\n",
    "Importacion de librerias necesarias para el entrenamiento y visualizacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5907d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_estructura_yolo():\n",
    "    base_dir = Path('yolo_dataset')\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "        (base_dir / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "        (base_dir / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    return base_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b567ae",
   "metadata": {},
   "source": [
    "## Estructura de datos YOLO\n",
    "\n",
    "Creacion de la estructura de carpetas requerida por YOLO para entrenamiento y validacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96d3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_anotaciones_yolo(csv_path, output_dir, split_name):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    img_dir = Path('conjunto_de_datos/ISIC_2019_Training_Input')\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        img_name = row['image'] + '.jpg'\n",
    "        img_path = img_dir / img_name\n",
    "        \n",
    "        if img_path.exists():\n",
    "            dest_img = output_dir / split_name / 'images' / img_name\n",
    "            shutil.copy(img_path, dest_img)\n",
    "            \n",
    "            img = Image.open(img_path)\n",
    "            w, h = img.size\n",
    "            \n",
    "            x_center = 0.5\n",
    "            y_center = 0.5\n",
    "            width = 0.8\n",
    "            height = 0.8\n",
    "            \n",
    "            label_path = output_dir / split_name / 'labels' / (row['image'] + '.txt')\n",
    "            with open(label_path, 'w') as f:\n",
    "                f.write(f'0 {x_center} {y_center} {width} {height}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f0e33",
   "metadata": {},
   "source": [
    "## Generacion de dataset\n",
    "\n",
    "Copia de imagenes y generacion de anotaciones en formato YOLO a partir de los subconjuntos CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9025d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = preparar_estructura_yolo()\n",
    "\n",
    "crear_anotaciones_yolo('conjunto_de_datos/train1_subset.csv', base_dir, 'train')\n",
    "crear_anotaciones_yolo('conjunto_de_datos/test1_subset.csv', base_dir, 'val')\n",
    "\n",
    "data_yaml = {\n",
    "    'path': str(base_dir.absolute()),\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'nc': 1,\n",
    "    'names': ['lesion']\n",
    "}\n",
    "\n",
    "yaml_path = base_dir / 'data.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43cc16",
   "metadata": {},
   "source": [
    "## Configuracion de modelos\n",
    "\n",
    "Definicion de los tres modelos YOLO a entrenar: nano, small y medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f18667",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = ['yolov8n', 'yolov8s', 'yolov8m']\n",
    "resultados = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394e5321",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "\n",
    "Ejecucion del entrenamiento para cada modelo con parametros optimizados para CPU: 15 epocas, imagenes de 320px, batch size 4 y un worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08b2d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.236 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.235 ğŸš€ Python-3.12.1 torch-2.9.1+cu128 CPU (Intel Xeon Platinum 8370C CPU @ 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/workspaces/DeepLearning/runs/detect/yolov8n4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3447.0Â±418.2 MB/s, size: 368.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspaces/DeepLearning/yolo_dataset/train/labels.cache... 100 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 92.9Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2726.1Â±302.1 MB/s, size: 347.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspaces/DeepLearning/yolo_dataset/val/labels.cache... 10 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 14.9Kit/s 0.0s\n",
      "Plotting labels to /workspaces/DeepLearning/runs/detect/yolov8n4/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/workspaces/DeepLearning/runs/detect/yolov8n4\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15         0G      1.765      2.235      1.718         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.7it/s 14.6s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.1it/s 0.6s1.7s\n",
      "                   all         10         10    0.00385          1      0.626      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15         0G      1.312      1.592      1.383         14        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.8it/s 14.1s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.9it/s 0.5s1.3s\n",
      "                   all         10         10      0.971        0.9      0.962      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15         0G      1.169      1.284       1.32          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.8it/s 14.2s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.8it/s 0.5s1.4s\n",
      "                   all         10         10      0.942          1      0.995      0.712\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/15         0G      1.197      1.214      1.307         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.7it/s 14.5s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.7it/s 0.5s1.4s\n",
      "                   all         10         10      0.996          1      0.995      0.713\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/15         0G      1.061      1.113       1.26          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.8it/s 14.3s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.5it/s 0.6s1.5s\n",
      "                   all         10         10      0.981          1      0.995      0.711\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/15         0G      1.141      1.682      1.513          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.8it/s 14.2s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.7it/s 0.5s1.4s\n",
      "                   all         10         10      0.584          1      0.902      0.347\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/15         0G      1.023       1.36      1.296          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.8it/s 14.0s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.6it/s 0.6s1.4s\n",
      "                   all         10         10      0.653          1      0.851      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/15         0G     0.9738      1.078      1.307          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.8it/s 14.2s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.1it/s 0.6s1.6s\n",
      "                   all         10         10      0.874          1      0.995        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/15         0G     0.8285     0.9797      1.178          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.8it/s 14.1s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.8it/s 0.5s1.4s\n",
      "                   all         10         10      0.809          1      0.995      0.902\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/15         0G     0.7445     0.8423      1.115          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.7it/s 14.4s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s1.9s\n",
      "                   all         10         10      0.993          1      0.995       0.86\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/15         0G     0.7499     0.8035      1.132          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.7it/s 14.3s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.7it/s 0.5s1.4s\n",
      "                   all         10         10      0.995          1      0.995      0.895\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/15         0G     0.6448     0.7575       1.03          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.7it/s 14.4s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.5it/s 0.6s1.4s\n",
      "                   all         10         10      0.995          1      0.995      0.947\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/15         0G     0.6331      0.734      1.077          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.7it/s 15.0s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.8it/s 0.5s1.4s\n",
      "                   all         10         10      0.995          1      0.995      0.946\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/15         0G     0.5416     0.6786     0.9755          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.7it/s 14.3s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.9it/s 0.5s1.3s\n",
      "                   all         10         10      0.995          1      0.995      0.945\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/15         0G     0.5544     0.6827      1.009          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.8it/s 14.2s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.7it/s 0.5s1.4s\n",
      "                   all         10         10      0.995          1      0.995      0.933\n",
      "\n",
      "15 epochs completed in 0.063 hours.\n",
      "Optimizer stripped from /workspaces/DeepLearning/runs/detect/yolov8n4/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /workspaces/DeepLearning/runs/detect/yolov8n4/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /workspaces/DeepLearning/runs/detect/yolov8n4/weights/best.pt...\n",
      "Ultralytics 8.3.235 ğŸš€ Python-3.12.1 torch-2.9.1+cu128 CPU (Intel Xeon Platinum 8370C CPU @ 2.80GHz)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.1it/s 0.6s1.4s\n",
      "                   all         10         10      0.995          1      0.995      0.947\n",
      "Speed: 0.8ms preprocess, 44.7ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1m/workspaces/DeepLearning/runs/detect/yolov8n4\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.236 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.235 ğŸš€ Python-3.12.1 torch-2.9.1+cu128 CPU (Intel Xeon Platinum 8370C CPU @ 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8s4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/workspaces/DeepLearning/runs/detect/yolov8s4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3548.3Â±625.9 MB/s, size: 314.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspaces/DeepLearning/yolo_dataset/train/labels.cache... 100 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 276.1Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3318.6Â±463.9 MB/s, size: 453.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspaces/DeepLearning/yolo_dataset/val/labels.cache... 10 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 4.8Kit/s 0.0s\n",
      "Plotting labels to /workspaces/DeepLearning/runs/detect/yolov8s4/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/workspaces/DeepLearning/runs/detect/yolov8s4\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15         0G      1.834      1.574      1.809         11        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.6s/it 39.1s1.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s3.4s\n",
      "                   all         10         10      0.759          1      0.943      0.684\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15         0G      1.279      1.304      1.362         12        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.5s/it 36.6s1.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s4.0s\n",
      "                   all         10         10      0.802          1      0.978      0.562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15         0G      1.125      1.059      1.218         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.4s/it 36.2s1.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s3.5s\n",
      "                   all         10         10      0.826          1      0.939       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/15         0G      1.384      1.142      1.351         12        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.4s/it 36.1s1.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.2s3.1s\n",
      "                   all         10         10      0.884          1      0.959      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/15         0G      1.197      1.134      1.245         11        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.4s/it 35.6s1.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.2s3.3s\n",
      "                   all         10         10      0.574          1      0.809      0.554\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/15         0G      1.072      1.252      1.318          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.4s/it 36.2s1.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s3.1s\n",
      "                   all         10         10      0.157      0.929      0.183      0.128\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 5 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "6 epochs completed in 0.064 hours.\n",
      "Optimizer stripped from /workspaces/DeepLearning/runs/detect/yolov8s4/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /workspaces/DeepLearning/runs/detect/yolov8s4/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /workspaces/DeepLearning/runs/detect/yolov8s4/weights/best.pt...\n",
      "Ultralytics 8.3.235 ğŸš€ Python-3.12.1 torch-2.9.1+cu128 CPU (Intel Xeon Platinum 8370C CPU @ 2.80GHz)\n",
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s3.1s\n",
      "                   all         10         10      0.759          1      0.943      0.684\n",
      "Speed: 0.7ms preprocess, 118.6ms inference, 0.0ms loss, 6.2ms postprocess per image\n",
      "Results saved to \u001b[1m/workspaces/DeepLearning/runs/detect/yolov8s4\u001b[0m\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 49.7MB 112.3MB/s 0.4s.4s<0.1ss\n",
      "New https://pypi.org/project/ultralytics/8.3.236 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.235 ğŸš€ Python-3.12.1 torch-2.9.1+cu128 CPU (Intel Xeon Platinum 8370C CPU @ 2.80GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/workspaces/DeepLearning/runs/detect/yolov8m, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3212.3Â±868.5 MB/s, size: 314.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspaces/DeepLearning/yolo_dataset/train/labels.cache... 100 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 100/100 133.6Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2456.0Â±1087.0 MB/s, size: 453.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspaces/DeepLearning/yolo_dataset/val/labels.cache... 10 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 9.5Kit/s 0.0s\n",
      "Plotting labels to /workspaces/DeepLearning/runs/detect/yolov8m/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/workspaces/DeepLearning/runs/detect/yolov8m\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15         0G      1.817       1.61      1.846         11        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.4s/it 1:253.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s7.4s\n",
      "                   all         10         10      0.813          1      0.986      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15         0G      1.428      1.585      1.471         12        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.4s/it 1:253.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s7.6s\n",
      "                   all         10         10       0.22        0.9      0.316      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15         0G      1.468      1.665      1.519         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.3s/it 1:243.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s7.4s\n",
      "                   all         10         10      0.174          1      0.763       0.22\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/15         0G      1.665      2.071      1.659         12        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.3s/it 1:233.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s7.4s\n",
      "                   all         10         10      0.116          1       0.84      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/15         0G       1.52      1.485      1.576         11        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.5s/it 1:283.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s7.6s\n",
      "                   all         10         10      0.405          1      0.452      0.157\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/15         0G      1.303        1.7      1.554          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.6s/it 1:293.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s7.5s\n",
      "                   all         10         10      0.201        0.9      0.359      0.276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/15         0G      1.075      1.143      1.383          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.5s/it 1:273.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s7.1s\n",
      "                   all         10         10      0.656          1      0.972      0.644\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/15         0G     0.9388      1.034      1.337          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.5s/it 1:283.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s7.3s\n",
      "                   all         10         10      0.413        0.8      0.679        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/15         0G     0.8239     0.8153      1.247          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.5s/it 1:273.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s7.4s\n",
      "                   all         10         10      0.975          1      0.995      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/15         0G     0.8277     0.7315       1.21          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.5s/it 1:273.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s8.2s\n",
      "                   all         10         10      0.987          1      0.995      0.935\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/15         0G      0.743     0.6516      1.166          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.5s/it 1:273.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s8.5s\n",
      "                   all         10         10       0.99          1      0.995      0.924\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/15         0G     0.7473     0.6224      1.177          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.5s/it 1:283.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s7.4s\n",
      "                   all         10         10      0.994          1      0.995      0.841\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/15         0G     0.6205      0.583      1.085          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.5s/it 1:273.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.7s7.2s\n",
      "                   all         10         10      0.994          1      0.995      0.886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/15         0G       0.62     0.5612      1.085          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.5s/it 1:283.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s7.7s\n",
      "                   all         10         10      0.995          1      0.995      0.935\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/15         0G     0.5419     0.5213      1.027          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 3.6s/it 1:293.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s7.2s\n",
      "                   all         10         10      0.995          1      0.995      0.985\n",
      "\n",
      "15 epochs completed in 0.377 hours.\n",
      "Optimizer stripped from /workspaces/DeepLearning/runs/detect/yolov8m/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from /workspaces/DeepLearning/runs/detect/yolov8m/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating /workspaces/DeepLearning/runs/detect/yolov8m/weights/best.pt...\n",
      "Ultralytics 8.3.235 ğŸš€ Python-3.12.1 torch-2.9.1+cu128 CPU (Intel Xeon Platinum 8370C CPU @ 2.80GHz)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1s/it 4.2s<10.7s\n",
      "                   all         10         10      0.995          1      0.995      0.985\n",
      "Speed: 0.6ms preprocess, 401.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1m/workspaces/DeepLearning/runs/detect/yolov8m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for modelo_nombre in modelos:\n",
    "    modelo = YOLO(f'{modelo_nombre}.pt')\n",
    "    \n",
    "    resultados_train = modelo.train(\n",
    "        data=str(yaml_path),\n",
    "        epochs=15,\n",
    "        imgsz=320,\n",
    "        batch=4,\n",
    "        name=modelo_nombre,\n",
    "        patience=5,\n",
    "        save=True,\n",
    "        device='cpu',\n",
    "        workers=1\n",
    "    )\n",
    "    \n",
    "    resultados[modelo_nombre] = resultados_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b547d4",
   "metadata": {},
   "source": [
    "## Visualizacion de metricas\n",
    "\n",
    "Funcion para generar graficas de las metricas de entrenamiento: loss, precision, recall y mAP. Estas graficas permiten identificar sobreajuste cuando las curvas de train y validacion divergen significativamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e248f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_metricas(modelo_nombre):\n",
    "    results_path = Path(f'runs/detect/{modelo_nombre}/results.csv')\n",
    "    \n",
    "    if not results_path.exists():\n",
    "        return\n",
    "    \n",
    "    df = pd.read_csv(results_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'Metricas de entrenamiento - {modelo_nombre}', fontsize=16)\n",
    "    \n",
    "    axes[0, 0].plot(df['epoch'], df['train/box_loss'], label='Train Box Loss')\n",
    "    axes[0, 0].plot(df['epoch'], df['val/box_loss'], label='Val Box Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Box Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    axes[0, 1].plot(df['epoch'], df['train/cls_loss'], label='Train Cls Loss')\n",
    "    axes[0, 1].plot(df['epoch'], df['val/cls_loss'], label='Val Cls Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].set_title('Classification Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    axes[1, 0].plot(df['epoch'], df['metrics/precision(B)'], label='Precision')\n",
    "    axes[1, 0].plot(df['epoch'], df['metrics/recall(B)'], label='Recall')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Score')\n",
    "    axes[1, 0].set_title('Precision y Recall')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    axes[1, 1].plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP50')\n",
    "    axes[1, 1].plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP50-95')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('mAP')\n",
    "    axes[1, 1].set_title('Mean Average Precision')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'metricas_{modelo_nombre}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1fb89c",
   "metadata": {},
   "source": [
    "Generacion de graficas individuales para cada modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f553dfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for modelo_nombre in modelos:\n",
    "    graficar_metricas(modelo_nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b306b4f",
   "metadata": {},
   "source": [
    "## Comparacion entre modelos\n",
    "\n",
    "Graficas comparativas que muestran el rendimiento relativo de los tres modelos en terminos de loss y mAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c7d376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def comparar_modelos():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    fig.suptitle('Comparacion entre modelos YOLO', fontsize=16)\n",
    "    \n",
    "    for modelo_nombre in modelos:\n",
    "        results_path = Path(f'runs/detect/{modelo_nombre}/results.csv')\n",
    "        \n",
    "        if results_path.exists():\n",
    "            df = pd.read_csv(results_path)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            \n",
    "            axes[0].plot(df['epoch'], df['val/box_loss'], label=modelo_nombre)\n",
    "            axes[1].plot(df['epoch'], df['metrics/mAP50(B)'], label=modelo_nombre)\n",
    "    \n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Validation Box Loss')\n",
    "    axes[0].set_title('Loss de validacion')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('mAP50')\n",
    "    axes[1].set_title('Mean Average Precision')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('comparacion_modelos.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "comparar_modelos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e7ed6",
   "metadata": {},
   "source": [
    "## Guardado de modelos\n",
    "\n",
    "Copia de los mejores pesos de cada modelo entrenado a una carpeta centralizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "258e58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('modelos_entrenados').mkdir(exist_ok=True)\n",
    "\n",
    "for modelo_nombre in modelos:\n",
    "    weight_path = Path(f'runs/detect/{modelo_nombre}/weights/best.pt')\n",
    "    if weight_path.exists():\n",
    "        dest = Path('modelos_entrenados') / f'{modelo_nombre}_best.pt'\n",
    "        shutil.copy(weight_path, dest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
